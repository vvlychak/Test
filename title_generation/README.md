# Генерация заголовков научных статей

## Описание проекта

Соревнование по мотивам курса ["Нейронные сети и обработка текста"](https://stepik.org/course/54098/syllabus). Предлагается решить задачу генерирования названия научной статьи по ее краткому описанию. Для решения задачи можно использовать любые подходы: seq2seq модели для суммаризации, предобученные на других датасетах модели (например, BERT, GPT-2 и т.д.) или придумать что-то еще. Требуется побить два бейзлайна. Код первого ("слабого") бейзлайна находится в [репозитории курса](https://github.com/sic-rus-ai/stepik-dl-nlp/tree/master/task11_kaggle). Это seq2seq модель (в качестве энкодера и декодера используется LSTM) с attention механизмом. Код сильного бейзлайна находится в секрете, известно только, что в его основе лежит предобученный BERT. Страница соревнования: https://www.kaggle.com/competitions/title-generation.

## Данные

В наличии были следующие данные:

Файлы:

- данные для обучения
- тестовые данные
- файл для генерации submission

Поля в датасете:

- текст аннотации
- заголовок статьи

## Задача
 
Построить модель генерации заголовка научной статьи по ее краткому описанию.

## Используемые библиотеки
*pandas, numpy, matplotlib, seaborn, sklearn, torch, transformers, bertviz, datasets, string, nltk, pickle*
